{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pascal Lexer",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGEPN7BYQfMc"
      },
      "source": [
        "# Lexer\n",
        "\n",
        "[Lexer](https://en.wikipedia.org/wiki/Lexical_analysis) jer deo kompajlera koji na osnovu izvornog koda formira niz tokena. Token je uređeni par (klasa, leksema). Leksema je karakter ili ključna reč koja ima funkciju u sintaksi programskog jezika. Upravo ta funkcija određuje klasu lekseme. Lekser će pročitati izvorni kod i to je jedini put kada će se to uraditi u čitavom procesu kompajliranja. Naredne faze kompajliranja zahtevaju samo formirani niz tokena..\n",
        "\n",
        "![pp-01](https://i.postimg.cc/SNmFQ6X0/pp-01.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCvhCTbnq_wH",
        "outputId": "8eadee0f-7bce-4bc3-975e-db52f7b437b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6idiapve0Dwr"
      },
      "source": [
        "from enum import Enum, auto"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DIb5pXdus1n"
      },
      "source": [
        "Class defines all possible lexeme classes that can be found in Pascal source code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Ti8oqs6zHXG"
      },
      "source": [
        "class Class(Enum):\n",
        "    TYPE          = auto()\n",
        "    ID            = auto()\n",
        "    INT           = auto()\n",
        "    REAL          = auto()\n",
        "    BOOLEAN       = auto()\n",
        "    CHAR          = auto()\n",
        "    STRING        = auto()\n",
        "    ARRAY         = auto()    # ?\n",
        "    OF            = auto()\n",
        "\n",
        "    PLUS          = auto()\n",
        "    MINUS         = auto()\n",
        "    ASTERISK      = auto()  # mnozenje\n",
        "    DIV           = auto()  # celobrojno deljenje\n",
        "    FWDSLASH      = auto()  # decimalno deljenje\n",
        "    MOD           = auto()\n",
        "\n",
        "    ABS           = auto()\n",
        "    ROUND         = auto()\n",
        "    INC           = auto()\n",
        "    DEC           = auto()\n",
        "\n",
        "    NOT = auto()\n",
        "    AND = auto()\n",
        "    OR = auto()\n",
        "    XOR = auto()\n",
        "\n",
        "    EQ = auto()             # =\n",
        "    NEQ = auto()            # <>\n",
        "    LT = auto()\n",
        "    GT = auto()\n",
        "    LTE = auto()\n",
        "    GTE = auto()\n",
        "\n",
        "    LPAREN        = auto()\n",
        "    RPAREN        = auto()\n",
        "    LBRACKET      = auto()\n",
        "    RBRACKET      = auto()\n",
        "    RANGE         = auto()\n",
        "\n",
        "    COMMA         = auto()\n",
        "    DOT           = auto()\n",
        "    COLON         = auto()\n",
        "    SEMICOLON     = auto()\n",
        "    ASSIGN        = auto()      # :=\n",
        "\n",
        "    VAR           = auto()  \n",
        "    PROCEDURE     = auto()\n",
        "    FUNCTION      = auto()\n",
        "    EXIT          = auto()\n",
        "    BEGIN         = auto()\n",
        "    END           = auto()     \n",
        "\n",
        "    IF            = auto()\n",
        "    THEN          = auto()\n",
        "    ELSE          = auto()\n",
        "\n",
        "    FOR           = auto()\n",
        "    TO            = auto()\n",
        "    DO            = auto()\n",
        "    WHILE         = auto()\n",
        "    REPEAT        = auto()\n",
        "    UNTIL         = auto()\n",
        "    BREAK         = auto()\n",
        "    CONTINUE      = auto()\n",
        "\n",
        "    EOF           = auto()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kICCJt51u3aa"
      },
      "source": [
        "** Token ** class is an ordered pair par (class, lexeme).\n",
        "\n",
        "Method **str** returns a string representation of a token. It is used in the debugging process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ok5GyT3VzI4x"
      },
      "source": [
        "class Token:\n",
        "    def __init__(self, class_, lexeme):\n",
        "        self.class_ = class_\n",
        "        self.lexeme = lexeme\n",
        "\n",
        "    def __str__(self):\n",
        "        return \"<{} {}>\".format(self.class_, self.lexeme)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R01tIB7ivLa6"
      },
      "source": [
        " **Lekser** class contains methods for lexical analysis of the Pascal source code.\n",
        "\n",
        "Method **lex** forms an array of tokens using the method **next_token**.\n",
        "\n",
        "Method **next_token** forms a token of the appropriarte class using **next_char** method.\n",
        "\n",
        "Method **next_char** moves the pointer to the next character.\n",
        "\n",
        "Method **read_keyword** forms a keyword token under the condition the current character is a letter.\n",
        "\n",
        "Method **read_string** forms a string token under the condition the current char is a '.\n",
        "\n",
        "Method **read_char** forms a string token under the condition the current char is a ' and the length is 1.\n",
        "\n",
        "Method **read_num** forms an int or real token depending on the format of the number.\n",
        "\n",
        "Method **read_space** moves the pointer to the first next non-space character.\n",
        "\n",
        "Method **die** is called in the case lexer came across an unexpected character."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2b3Imf7y_cO"
      },
      "source": [
        "class Lexer:\n",
        "    def __init__(self, text):\n",
        "        self.text = text\n",
        "        self.len = len(text)\n",
        "        self.pos = -1\n",
        "\n",
        "    def read_space(self):\n",
        "        while self.pos + 1 < self.len and self.text[self.pos + 1].isspace():\n",
        "            self.next_char()\n",
        "\n",
        "    def read_num(self):\n",
        "        lexeme = self.text[self.pos]\n",
        "        while self.pos + 1 < self.len and self.text[self.pos + 1].isdigit():\n",
        "            lexeme += self.next_char()\n",
        "        if self.text[self.pos + 1] == '.' and self.text[self.pos + 2] != '.':\n",
        "            lexeme += self.next_char()\n",
        "            return read_real(lexeme)\n",
        "        return Token(Class.INT, int(lexeme)) \n",
        "\n",
        "    def read_real(self, lexeme):\n",
        "        while self.pos + 1 < self.len and self.text[self.pos + 1].isdigit():\n",
        "            lexeme += self.next_char()\n",
        "        return Token(Class.REAL, real(lexeme))\n",
        "\n",
        "    def read_char(self): \n",
        "        self.pos += 1\n",
        "        lexeme = self.text[self.pos]\n",
        "        self.pos += 1\n",
        "        return lexeme\n",
        "\n",
        "    def read_string(self): \n",
        "        lexeme = ''\n",
        "        while self.pos + 1 < self.len and self.text[self.pos + 1] != '\\'':\n",
        "            lexeme += self.next_char()\n",
        "        self.pos += 1\n",
        "        return lexeme\n",
        "\n",
        "    def read_keyword(self):\n",
        "        lexeme = self.text[self.pos]\n",
        "        while self.pos + 1 < self.len and self.text[self.pos + 1].isalnum():\n",
        "            lexeme += self.next_char()\n",
        "        if lexeme == 'begin':\n",
        "            return Token(Class.BEGIN, lexeme)\n",
        "        elif lexeme == 'end':                           \n",
        "            return Token(Class.END, lexeme)\n",
        "        elif lexeme == 'procedure':\n",
        "            return Token(Class.PROCEDURE, lexeme)\n",
        "        elif lexeme == 'function':\n",
        "            return Token(Class.FUNCTION, lexeme)\n",
        "        elif lexeme == 'exit':\n",
        "            return Token(Class.EXIT, lexeme)\n",
        "        elif lexeme == 'var':\n",
        "            return Token(Class.VAR, lexeme)\n",
        "        elif lexeme == 'div':\n",
        "            return Token(Class.DIV, lexeme)\n",
        "        elif lexeme == 'mod':\n",
        "            return Token(Class.MOD, lexeme)\n",
        "        elif lexeme == 'true' or lexeme == 'false':\n",
        "            return Token(Class.BOOLEAN, lexeme)\n",
        "        elif lexeme == 'not':\n",
        "            return Token(Class.NOT, lexeme)\n",
        "        elif lexeme == 'and':\n",
        "            return Token(Class.AND, lexeme)\n",
        "        elif lexeme == 'or':\n",
        "            return Token(Class.OR, lexeme)\n",
        "        elif lexeme == 'xor':\n",
        "            return Token(Class.XOR, lexeme)\n",
        "        elif lexeme == 'array':\n",
        "            return Token(Class.ARRAY, lexeme)\n",
        "        elif lexeme == 'of':\n",
        "            return Token(Class.OF, lexeme)\n",
        "        elif lexeme == 'if':\n",
        "            return Token(Class.IF, lexeme)\n",
        "        elif lexeme == 'then':\n",
        "            return Token(Class.THEN, lexeme)\n",
        "        elif lexeme == 'else':\n",
        "            return Token(Class.ELSE, lexeme)\n",
        "        elif lexeme == 'while':\n",
        "            return Token(Class.WHILE, lexeme)\n",
        "        elif lexeme == 'for':\n",
        "            return Token(Class.FOR, lexeme)\n",
        "        elif lexeme == 'to':\n",
        "            return Token(Class.TO, lexeme)\n",
        "        elif lexeme == 'do':\n",
        "            return Token(Class.DO, lexeme)\n",
        "        elif lexeme == 'repeat':\n",
        "            return Token(Class.REPEAT, lexeme)\n",
        "        elif lexeme == 'until':\n",
        "            return Token(Class.UNTIL, lexeme)\n",
        "        elif lexeme == 'Break':\n",
        "            return Token(Class.BREAK, lexeme)\n",
        "        elif lexeme == 'Continue':\n",
        "            return Token(Class.CONTINUE, lexeme)\n",
        "        elif lexeme == 'return':\n",
        "            return Token(Class.RETURN, lexeme)\n",
        "        elif lexeme == 'integer' or lexeme == 'real' or lexeme == 'char' or lexeme == 'string' or lexeme == 'boolean':\n",
        "            return Token(Class.TYPE, lexeme)\n",
        "        return Token(Class.ID, lexeme)\n",
        "\n",
        "    def next_char(self):\n",
        "        self.pos += 1\n",
        "        if self.pos >= self.len:\n",
        "            return None\n",
        "        return self.text[self.pos]\n",
        "\n",
        "    def peek(self, step):\n",
        "        peek_pos = self.pos + step\n",
        "        if peek_pos >= self.len:\n",
        "            return None\n",
        "        return self.text[peek_pos]   \n",
        "\n",
        "    def next_token(self):\n",
        "        self.read_space()\n",
        "        curr = self.next_char()\n",
        "        if curr is None:\n",
        "            return Token(Class.EOF, curr)\n",
        "        token = None\n",
        "        if curr.isalpha():\n",
        "            token = self.read_keyword()\n",
        "        elif curr.isdigit():\n",
        "            token = self.read_num()\n",
        "        elif curr == ':' and self.peek(1) == '=':\n",
        "                self.next_char()\n",
        "                token = Token(Class.ASSIGN, ':=')\n",
        "        elif curr == '\\'':\n",
        "            self.pos += 1\n",
        "            if self.peek(1) == '\\'':\n",
        "                self.pos -= 1\n",
        "                token = Token(Class.CHAR, self.read_char())\n",
        "            else:\n",
        "                self.pos -= 1\n",
        "                token = Token(Class.STRING, self.read_string())\n",
        "        elif curr == '+':\n",
        "            token = Token(Class.PLUS, curr)\n",
        "        elif curr == '-':\n",
        "            token = Token(Class.MINUS, curr)\n",
        "        elif curr == '*':\n",
        "            token = Token(Class.ASTERISK, curr)\n",
        "        elif curr == '/':\n",
        "            token = Token(Class.FWDSLASH, curr)\n",
        "        elif curr == '%':\n",
        "            token = Token(Class.PERCENT, curr)\n",
        "        elif curr == '=':\n",
        "                token = Token(Class.EQ, '=')\n",
        "        elif curr == '<':\n",
        "            if self.peek(1) == '=':\n",
        "                self.next_char()\n",
        "                token = Token(Class.LTE, '<=')\n",
        "            elif self.peek(1) == '>':\n",
        "                self.next.char()\n",
        "                token = Token(Class.NEQ, '<>')\n",
        "            else:\n",
        "                token = Token(Class.LT, '<')\n",
        "        elif curr == '>':\n",
        "            if self.peek(1) == '=':\n",
        "                self.next_char()\n",
        "                token = Token(Class.GTE, '>=')\n",
        "            else:\n",
        "                token = Token(Class.GT, '>')\n",
        "        elif curr == '(':\n",
        "            token = Token(Class.LPAREN, curr)\n",
        "        elif curr == ')':\n",
        "            token = Token(Class.RPAREN, curr)\n",
        "        elif curr == '[':\n",
        "            token = Token(Class.LBRACKET, curr)\n",
        "        elif curr == ']':\n",
        "            token = Token(Class.RBRACKET, curr)\n",
        "        elif curr == ';':\n",
        "            token = Token(Class.SEMICOLON, curr)\n",
        "        elif curr == ':':\n",
        "            token = Token(Class.COLON, curr)\n",
        "        elif curr == ',':\n",
        "            token = Token(Class.COMMA, curr)\n",
        "        elif curr == '.':\n",
        "            token = Token(Class.DOT, curr)\n",
        "            if self.peek(1) == '.':\n",
        "                self.next_char()\n",
        "                token = Token(Class.RANGE, '..')\n",
        "        else:\n",
        "            self.die(curr)\n",
        "        return token\n",
        "\n",
        "    def lex(self):\n",
        "        tokens = []\n",
        "        while True:\n",
        "            curr = self.next_token()\n",
        "            tokens.append(curr)\n",
        "            if curr.class_ == Class.EOF:\n",
        "                break\n",
        "        return tokens\n",
        "\n",
        "    def die(self, char):\n",
        "        raise SystemExit(\"Unexpected character: {}\".format(char))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}